{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrT5pXqDQrDB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "auTDiqr6xncq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader,KNNBasic\n",
        "from surprise.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uKAXfS_xPfT",
        "outputId": "9803dcaf-fcaf-4470-91a4-562d5026edf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-surprise in /usr/local/lib/python3.11/dist-packages (1.1.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-surprise) (1.13.1)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-surprise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7Qn4_TReBgw",
        "outputId": "1715828e-050c-44a5-c518-a06298c95755"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Customer_id  Age  Gender  Income  Credit_score Credit_score_category  \\\n",
            "0       C0124   66    Male  108296           627                  Fair   \n",
            "1       C0119   25    Male   88437           589                  Fair   \n",
            "2        C044   21    Male   93447           832             Excellent   \n",
            "3       C0148   55    Male  138441           845             Excellent   \n",
            "4       C0196   22  Female  184615           606                  Fair   \n",
            "\n",
            "   Loan_amount  Interest_rate  Loan_term  Loan_type  ...  Transaction_freq  \\\n",
            "0       225098           1.82         12  Education  ...                 4   \n",
            "1       109731          10.80         60       Auto  ...                10   \n",
            "2       261695          12.24         48       Auto  ...                 7   \n",
            "3       368030           5.67         48       Auto  ...                 8   \n",
            "4       257577           5.96         12   Business  ...                 6   \n",
            "\n",
            "   Product_id             Product_names  Interaction_type Interaction_date  \\\n",
            "0        P003               Credit Card         purchased       2024-06-03   \n",
            "1        P015          Home Equity Line         purchased       2023-05-25   \n",
            "2        P028   Debt Consolidation Loan         purchased       2024-04-08   \n",
            "3        P035    Real Estate Investment         purchased       2024-12-15   \n",
            "4        P036  International Investment            viewed       2023-02-04   \n",
            "\n",
            "  Interaction_month  Interaction_year  Transaction_type_le  KMeans_Cluster  \\\n",
            "0                 6              2024                    0               2   \n",
            "1                 5              2023                    0               1   \n",
            "2                 4              2024                    1               3   \n",
            "3                12              2024                    0               1   \n",
            "4                 2              2023                    0               5   \n",
            "\n",
            "  Transaction_Type_Encoded  \n",
            "0                        0  \n",
            "1                        0  \n",
            "2                        1  \n",
            "3                        0  \n",
            "4                        0  \n",
            "\n",
            "[5 rows x 28 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file\n",
        "df = pd.read_csv('Loan_data_k.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "6YqJ4KIEjT9r"
      },
      "outputs": [],
      "source": [
        "df.loc[df['Product_id'] == 102, 'Product_name'] = 'Premium Checking Account'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMxHogVXfuKA",
        "outputId": "5a7bf0e2-5cc0-466a-f2f6-e4382a542278"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<surprise.prediction_algorithms.knns.KNNBasic at 0x7c8db0a93f10>"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "interaction_type_mapping={'Viewed': 1, 'Clicked': 2, 'Purchased': 3}\n",
        "df[\"Interaction_Type\"]=df[\"Interaction_type\"].map(interaction_type_mapping)\n",
        "\n",
        "reader=Reader(rating_scale=(1,3))\n",
        "data = Dataset.load_from_df(df[['Customer_id', 'Product_id', 'Interaction_Type']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "\n",
        "model = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
        "model.fit(trainset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "weK2kdcTlQVr"
      },
      "outputs": [],
      "source": [
        "product_mapping = {\n",
        "    \"P001\": \"Savings Account\",\n",
        "    \"P002\": \"Premium Checking Account\",\n",
        "    \"P003\": \"Credit Card\",\n",
        "    \"P004\": \"Personal Loan\",\n",
        "    \"P005\": \"Home Loan\",\n",
        "    \"P006\": \"Auto Loan\",\n",
        "    \"P007\": \"Business Loan\",\n",
        "    \"P008\": \"Student Loan\",\n",
        "    \"P009\": \"Investment Fund\",\n",
        "    \"P010\": \"Retirement Plan\",\n",
        "    \"P011\": \"Insurance Policy\",\n",
        "    \"P012\": \"Mutual Fund\",\n",
        "    \"P013\": \"Bond\",\n",
        "    \"P014\": \"Certificate of Deposit\",\n",
        "    \"P015\": \"Home Equity Line\",\n",
        "    \"P016\": \"Mortgage Refinance\",\n",
        "    \"P017\": \"Business Credit Line\",\n",
        "    \"P018\": \"Auto Refinance\",\n",
        "    \"P019\": \"Home Improvement Loan\",\n",
        "    \"P020\": \"Gold Loan\",\n",
        "    \"P021\": \"Cash Credit\",\n",
        "    \"P022\": \"Short-Term Loan\",\n",
        "    \"P023\": \"Long-Term Loan\",\n",
        "    \"P024\": \"Travel Loan\",\n",
        "    \"P025\": \"Medical Loan\",\n",
        "    \"P026\": \"Emergency Loan\",\n",
        "    \"P027\": \"Holiday Loan\",\n",
        "    \"P028\": \"Debt Consolidation Loan\",\n",
        "    \"P029\": \"Small Business Loan\",\n",
        "    \"P030\": \"Agricultural Loan\",\n",
        "    \"P031\": \"Technology Loan\",\n",
        "    \"P032\": \"Education Savings Plan\",\n",
        "    \"P033\": \"Wealth Management\",\n",
        "    \"P034\": \"Stock Investment\",\n",
        "    \"P035\": \"Real Estate Investment\",\n",
        "    \"P036\": \"International Investment\",\n",
        "    \"P037\": \"Fixed Deposit\",\n",
        "    \"P038\": \"Recurring Deposit\",\n",
        "    \"P039\": \"Loan Against Property\",\n",
        "    \"P040\": \"Gold Investment\",\n",
        "    \"P041\": \"Retirement Savings\",\n",
        "    \"P042\": \"High-Yield Savings Account\",\n",
        "    \"P043\": \"Money Market Account\",\n",
        "    \"P044\": \"Insurance Savings\",\n",
        "    \"P045\": \"Pension Plan\",\n",
        "    \"P046\": \"Child Education Fund\",\n",
        "    \"P047\": \"Healthcare Savings\",\n",
        "    \"P048\": \"Property Investment\",\n",
        "    \"P049\": \"Auto Insurance\"\n",
        "}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i91r9Jvtkzq2",
        "outputId": "03bf6244-3237-4684-8cad-127954bf12b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Product_Id            Product_Name\n",
            "0       P020               Gold Loan\n",
            "1       P010         Retirement Plan\n",
            "2       P014  Certificate of Deposit\n",
            "3       P003             Credit Card\n",
            "4       P007           Business Loan\n"
          ]
        }
      ],
      "source": [
        "def recommend_products(customer_id, model, interaction_data, product_mapping, n=5):\n",
        "    all_products = set(interaction_data['Product_id'].unique())\n",
        "    interacted_products = set(interaction_data[interaction_data['Customer_id'] == customer_id]['Product_id'])\n",
        "    products_to_predict = list(all_products - interacted_products)\n",
        "    predictions = [model.predict(customer_id, product_id) for product_id in products_to_predict]\n",
        "    top_n_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
        "    recommended_product_ids = [pred.iid for pred in top_n_predictions]\n",
        "    recommended_products = pd.DataFrame({\n",
        "        'Product_Id': recommended_product_ids,\n",
        "        'Product_Name': [product_mapping.get(pid, 'Unknown') for pid in recommended_product_ids]\n",
        "    })\n",
        "    return recommended_products\n",
        "\n",
        "Customer_Id = 'C053'\n",
        "recommended_products = recommend_products(Customer_Id, model, df, product_mapping, n=5)\n",
        "print(recommended_products)\n",
        "\n",
        "predictions = model.test(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQrGZXAGP68G"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpZlRsPjP7Qs",
        "outputId": "c4a731ad-556c-406d-c0be-4a5284b6112d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Precision@5: 1.0\n",
            "Recall@5: 1.0\n",
            "MAP@5: 1.0\n",
            "NDCG@5: 0.7103099178571526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-90-c0e0cd6cc30b>:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n",
            "<ipython-input-90-c0e0cd6cc30b>:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n",
            "<ipython-input-90-c0e0cd6cc30b>:79: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split\n",
        "\n",
        "# Sample Data\n",
        "data_dict = {\n",
        "    'user': ['U001', 'U002', 'U001', 'U003', 'U004', 'U005', 'U001', 'U003', 'U002', 'U004'],\n",
        "    'item': ['I001', 'I002', 'I003', 'I001', 'I005', 'I002', 'I004', 'I003', 'I005', 'I004'],\n",
        "    'rating': [5, 4, 3, 2, 1, 4, 2, 5, 3, 4]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df1 = pd.DataFrame(data_dict)\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "csv_file_path = 'sample_data.csv'\n",
        "df1.to_csv(csv_file_path, index=False)\n",
        "\n",
        "# Load the data\n",
        "reader = Reader(line_format='user item rating', sep=',', rating_scale=(1, 5))\n",
        "data1 = Dataset.load_from_df(df1[['user', 'item', 'rating']], reader=reader)\n",
        "\n",
        "# Split the data\n",
        "trainset, testset = train_test_split(data1, test_size=0.25)\n",
        "\n",
        "# Train the KNNBasic model\n",
        "model = KNNBasic(sim_options={'name': 'cosine', 'user_based': True})\n",
        "model.fit(trainset)\n",
        "\n",
        "# Generate predictions\n",
        "predictions = model.test(testset)\n",
        "\n",
        "# Precision and Recall@k\n",
        "def precision_recall_at_k(predictions, k=5, threshold=3.5):\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'true_r', 'est', 'details'])\n",
        "    pred_df['is_relevant'] = pred_df['true_r'] >= threshold\n",
        "    pred_df = pred_df.sort_values(by=['uid', 'est'], ascending=[True, False])\n",
        "    top_k = pred_df.groupby('uid').head(k)\n",
        "\n",
        "    precision = top_k.groupby('uid')['is_relevant'].mean().mean()\n",
        "    recall = top_k.groupby('uid')['is_relevant'].sum() / pred_df.groupby('uid')['is_relevant'].sum()\n",
        "    recall = recall.mean()\n",
        "    return precision, recall\n",
        "\n",
        "# Mean Average Precision (MAP@k)\n",
        "def mean_average_precision(predictions, k=5, threshold=3.5):\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'true_r', 'est', 'details'])\n",
        "    pred_df['is_relevant'] = pred_df['true_r'] >= threshold\n",
        "    pred_df = pred_df.sort_values(by=['uid', 'est'], ascending=[True, False])\n",
        "\n",
        "    map_scores = []\n",
        "    for uid, user_data in pred_df.groupby('uid'):\n",
        "        user_data = user_data.head(k)\n",
        "        if user_data['is_relevant'].sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [\n",
        "            user_data.iloc[:i+1]['is_relevant'].mean() for i in range(len(user_data))\n",
        "        ]\n",
        "        ap = sum(precisions * user_data['is_relevant']) / user_data['is_relevant'].sum()\n",
        "        map_scores.append(ap)\n",
        "\n",
        "    return sum(map_scores) / len(map_scores) if map_scores else 0\n",
        "\n",
        "# Normalized Discounted Cumulative Gain (NDCG@k)\n",
        "import numpy as np\n",
        "\n",
        "def ndcg_at_k(predictions, k=5, threshold=3.5):\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'true_r', 'est', 'details'])\n",
        "    pred_df['is_relevant'] = pred_df['true_r'] >= threshold\n",
        "    pred_df = pred_df.sort_values(by=['uid', 'est'], ascending=[True, False])\n",
        "\n",
        "    ndcg_scores = []\n",
        "    for uid, user_data in pred_df.groupby('uid'):\n",
        "        user_data = user_data.head(k)\n",
        "        if user_data['is_relevant'].sum() == 0:\n",
        "            continue\n",
        "\n",
        "        user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n",
        "        dcg = user_data['dcg'].sum()\n",
        "\n",
        "        idcg = sum(1 / np.log2(i + 2) for i in range(int(user_data['is_relevant'].sum())))\n",
        "        ndcg_scores.append(dcg / idcg if idcg > 0 else 0)\n",
        "\n",
        "    return sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0\n",
        "\n",
        "# Calculate Metrics\n",
        "precision, recall = precision_recall_at_k(predictions, k=5)\n",
        "map_score = mean_average_precision(predictions, k=5)\n",
        "ndcg_score = ndcg_at_k(predictions, k=5)\n",
        "\n",
        "# Display Metrics\n",
        "print(f\"Precision@5: {precision}\")\n",
        "print(f\"Recall@5: {recall}\")\n",
        "print(f\"MAP@5: {map_score}\")\n",
        "print(f\"NDCG@5: {ndcg_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5--YmklRapP",
        "outputId": "37af3176-1d95-4dc3-83a7-8f525dbb1d08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the msd similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the pearson similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "  Product_Id              Product_Name\n",
            "0       P020                 Gold Loan\n",
            "1       P010           Retirement Plan\n",
            "2       P036  International Investment\n",
            "3       P014    Certificate of Deposit\n",
            "4       P007             Business Loan\n"
          ]
        }
      ],
      "source": [
        "interaction_type_mapping={'Viewed': 1, 'Clicked': 2, 'Purchased': 3}\n",
        "df[\"Interaction_Type\"]=df[\"Interaction_type\"].map(interaction_type_mapping)\n",
        "\n",
        "reader=Reader(rating_scale=(1,3))\n",
        "data = Dataset.load_from_df(df[['Customer_id', 'Product_id', 'Interaction_Type']], reader)\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "param_grid={\n",
        "    \"k\":[5,10,15],\n",
        "    \"sim_options\":{\"name\":[\"cosine\",\"msd\",\"pearson\"],\n",
        "    \"user_based\":[True,False]}\n",
        "}\n",
        "\n",
        "gs=GridSearchCV(KNNBasic,param_grid,measures=[\"rmse\"],cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "best_knn_model = gs.best_estimator[\"rmse\"]\n",
        "best_knn_model.fit(trainset)\n",
        "\n",
        "def recommend_products(customer_id, model, interaction_data, product_mapping, n=5):\n",
        "    all_products = set(interaction_data['Product_id'].unique())\n",
        "    interacted_products = set(interaction_data[interaction_data['Customer_id'] == customer_id]['Product_id'])\n",
        "    products_to_predict = list(all_products - interacted_products)\n",
        "    predictions = [model.predict(customer_id, product_id) for product_id in products_to_predict]\n",
        "    top_n_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
        "    recommended_product_ids = [pred.iid for pred in top_n_predictions]\n",
        "    recommended_products = pd.DataFrame({\n",
        "        'Product_Id': recommended_product_ids,\n",
        "        'Product_Name': [product_mapping.get(pid, 'Unknown') for pid in recommended_product_ids]\n",
        "    })\n",
        "    return recommended_products\n",
        "\n",
        "Customer_Id = 'C0124'\n",
        "recommended_products = recommend_products(Customer_Id, model, df, product_mapping, n=5)\n",
        "print(recommended_products)\n",
        "\n",
        "predictions = model.test(testset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgbWle-6cv3p",
        "outputId": "16ca823c-446f-42e6-e884-5e649de1ce95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Parameters: {'k': 5, 'sim_options': {'name': 'cosine', 'user_based': True}}\n",
            "Computing the cosine similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "User: U003, Item: I003, True Rating: 5.0, Predicted Rating: 2.857142857142857\n",
            "User: U001, Item: I001, True Rating: 5.0, Predicted Rating: 2.857142857142857\n",
            "User: U001, Item: I003, True Rating: 3.0, Predicted Rating: 2.857142857142857\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "from surprise.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Sample Data\n",
        "data_dict = {\n",
        "    'user': ['U001', 'U002', 'U001', 'U003', 'U004', 'U005', 'U001', 'U003', 'U002', 'U004'],\n",
        "    'item': ['I001', 'I002', 'I003', 'I001', 'I005', 'I002', 'I004', 'I003', 'I005', 'I004'],\n",
        "    'rating': [5, 4, 3, 2, 1, 4, 2, 5, 3, 4]\n",
        "}\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data_dict)\n",
        "\n",
        "# Load the data into a Surprise dataset\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "data = Dataset.load_from_df(df[['user', 'item', 'rating']], reader)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "\n",
        "# Define the parameter grid for GridSearchCV\n",
        "param_grid = {\n",
        "    \"k\": [5, 10, 15, 20],  # Number of neighbors\n",
        "    \"sim_options\": {\n",
        "        \"name\": [\"cosine\", \"msd\", \"pearson\"],  # Similarity measures\n",
        "        \"user_based\": [True, False]  # User-based or item-based collaborative filtering\n",
        "    }\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV\n",
        "gs = GridSearchCV(KNNBasic, param_grid, measures=[\"rmse\", \"mae\"], cv=3, n_jobs=-1)\n",
        "gs.fit(data)  # Pass the full Surprise dataset here\n",
        "\n",
        "# Retrieve the best model\n",
        "best_knn_model = gs.best_estimator[\"rmse\"]\n",
        "print(f\"Best Parameters: {gs.best_params['rmse']}\")\n",
        "\n",
        "# Train the best model on the training set\n",
        "best_knn_model.fit(trainset)\n",
        "\n",
        "# Generate predictions using the test set\n",
        "predictions = best_knn_model.test(testset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2I2HVknD9Tfx",
        "outputId": "5f63f56e-3787-4d36-ca30-6d75ca38e78e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision@5: 0.75\n",
            "Recall@5: 1.0\n",
            "MAP@5: 1.0\n",
            "NDCG@5: 0.8154648767857288\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-98-8812b2b7b36b>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n",
            "<ipython-input-98-8812b2b7b36b>:47: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n"
          ]
        }
      ],
      "source": [
        "# Precision and Recall@k\n",
        "def precision_recall_at_k(predictions, k=5, threshold=3.5):\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'true_r', 'est', 'details'])\n",
        "    pred_df['is_relevant'] = pred_df['true_r'] >= threshold\n",
        "    pred_df = pred_df.sort_values(by=['uid', 'est'], ascending=[True, False])\n",
        "    top_k = pred_df.groupby('uid').head(k)\n",
        "\n",
        "    precision = top_k.groupby('uid')['is_relevant'].mean().mean()\n",
        "    recall = top_k.groupby('uid')['is_relevant'].sum() / pred_df.groupby('uid')['is_relevant'].sum()\n",
        "    recall = recall.mean()\n",
        "    return precision, recall\n",
        "\n",
        "# Mean Average Precision (MAP@k)\n",
        "def mean_average_precision(predictions, k=5, threshold=3.5):\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'true_r', 'est', 'details'])\n",
        "    pred_df['is_relevant'] = pred_df['true_r'] >= threshold\n",
        "    pred_df = pred_df.sort_values(by=['uid', 'est'], ascending=[True, False])\n",
        "\n",
        "    map_scores = []\n",
        "    for uid, user_data in pred_df.groupby('uid'):\n",
        "        user_data = user_data.head(k)\n",
        "        if user_data['is_relevant'].sum() == 0:\n",
        "            continue\n",
        "\n",
        "        precisions = [\n",
        "            user_data.iloc[:i+1]['is_relevant'].mean() for i in range(len(user_data))\n",
        "        ]\n",
        "        ap = sum(precisions * user_data['is_relevant']) / user_data['is_relevant'].sum()\n",
        "        map_scores.append(ap)\n",
        "\n",
        "    return sum(map_scores) / len(map_scores) if map_scores else 0\n",
        "\n",
        "# Normalized Discounted Cumulative Gain (NDCG@k)\n",
        "import numpy as np\n",
        "\n",
        "def ndcg_at_k(predictions, k=5, threshold=3.5):\n",
        "    pred_df = pd.DataFrame(predictions, columns=['uid', 'iid', 'true_r', 'est', 'details'])\n",
        "    pred_df['is_relevant'] = pred_df['true_r'] >= threshold\n",
        "    pred_df = pred_df.sort_values(by=['uid', 'est'], ascending=[True, False])\n",
        "\n",
        "    ndcg_scores = []\n",
        "    for uid, user_data in pred_df.groupby('uid'):\n",
        "        user_data = user_data.head(k)\n",
        "        if user_data['is_relevant'].sum() == 0:\n",
        "            continue\n",
        "\n",
        "        user_data['dcg'] = user_data['is_relevant'] / np.log2(user_data.index + 2)\n",
        "        dcg = user_data['dcg'].sum()\n",
        "\n",
        "        idcg = sum(1 / np.log2(i + 2) for i in range(int(user_data['is_relevant'].sum())))\n",
        "        ndcg_scores.append(dcg / idcg if idcg > 0 else 0)\n",
        "\n",
        "    return sum(ndcg_scores) / len(ndcg_scores) if ndcg_scores else 0\n",
        "\n",
        "# Calculate Metrics\n",
        "precision, recall = precision_recall_at_k(predictions, k=5)\n",
        "map_score = mean_average_precision(predictions, k=5)\n",
        "ndcg_score = ndcg_at_k(predictions, k=5)\n",
        "\n",
        "# Display Metrics\n",
        "print(f\"Precision@5: {precision}\")\n",
        "print(f\"Recall@5: {recall}\")\n",
        "print(f\"MAP@5: {map_score}\")\n",
        "print(f\"NDCG@5: {ndcg_score}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "E7jbLnlekEmv"
      },
      "outputs": [],
      "source": [
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0p67_T1ykzwd"
      },
      "outputs": [],
      "source": [
        "with open(\"model_knn.pkl\",\"wb\") as f:\n",
        "    pickle.dump(model, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "i9LrvyLqc_CK"
      },
      "outputs": [],
      "source": [
        "with open(\"model_knn.pkl\", \"rb\") as f:\n",
        "    loaded_model = pickle.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XECaHJvAk6bF",
        "outputId": "58327b5d-7fda-4ab7-c800-9df9701d356e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.41.1)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (17.0.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (13.9.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.5)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.21.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2024.12.14)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sQ_1gQrs-iX",
        "outputId": "ea889041-3707-4bb0-d066-60f086ca46cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKCcfRiorqIq",
        "outputId": "5a832466-f9d1-4a94-a191-94d93ebc6a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35.237.116.74\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9FDj1R_zr8GS",
        "outputId": "04f2e9e7-576a-40ad-a111-bd0f486180bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "st.write(\"hi sandy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7D2zHnHtrFS",
        "outputId": "b75fa98d-63a6-4f6b-c221-7a73cdeab9c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.237.116.74:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0Kyour url is: https://free-suits-sit.loca.lt\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "! streamlit run app.py & npx localtunnel --port 8501\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naW9LDQuulHl",
        "outputId": "0ce0f807-cf67-4f4a-886f-e2757dd335a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-01-22 06:37:46--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok...\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 99.83.220.108, 13.248.244.96, 75.2.60.68, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|99.83.220.108|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-01-22 06:37:46 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok...\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vv3rYXs3uzMz"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, KNNBasic\n",
        "import pickle\n",
        "\n",
        "# Load pre-trained KNN model\n",
        "with open(\"gs.pkl\", \"rb\") as f:\n",
        "    model = pickle.load(f)\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('Loan_data_k.csv')\n",
        "\n",
        "# Mapping product IDs to product names\n",
        "product_mapping = {\n",
        "    \"P001\": \"Savings Account\", \"P002\": \"Premium Checking Account\", \"P003\": \"Credit Card\", \n",
        "    \"P004\": \"Personal Loan\", \"P005\": \"Home Loan\", \"P006\": \"Auto Loan\", \"P007\": \"Business Loan\", \n",
        "    \"P008\": \"Student Loan\", \"P009\": \"Investment Fund\", \"P010\": \"Retirement Plan\", \"P011\": \"Insurance Policy\", \n",
        "    \"P012\": \"Mutual Fund\", \"P013\": \"Bond\", \"P014\": \"Certificate of Deposit\", \"P015\": \"Home Equity Line\", \n",
        "    \"P016\": \"Mortgage Refinance\", \"P017\": \"Business Credit Line\", \"P018\": \"Auto Refinance\", \n",
        "    \"P019\": \"Home Improvement Loan\", \"P020\": \"Gold Loan\", \"P021\": \"Cash Credit\", \"P022\": \"Short-Term Loan\", \n",
        "    \"P023\": \"Long-Term Loan\", \"P024\": \"Travel Loan\", \"P025\": \"Medical Loan\", \"P026\": \"Emergency Loan\", \n",
        "    \"P027\": \"Holiday Loan\", \"P028\": \"Debt Consolidation Loan\", \"P029\": \"Small Business Loan\", \n",
        "    \"P030\": \"Agricultural Loan\", \"P031\": \"Technology Loan\", \"P032\": \"Education Savings Plan\", \n",
        "    \"P033\": \"Wealth Management\", \"P034\": \"Stock Investment\", \"P035\": \"Real Estate Investment\", \n",
        "    \"P036\": \"International Investment\", \"P037\": \"Fixed Deposit\", \"P038\": \"Recurring Deposit\", \n",
        "    \"P039\": \"Loan Against Property\", \"P040\": \"Gold Investment\", \"P041\": \"Retirement Savings\", \n",
        "    \"P042\": \"High-Yield Savings Account\", \"P043\": \"Money Market Account\", \"P044\": \"Insurance Savings\", \n",
        "    \"P045\": \"Pension Plan\", \"P046\": \"Child Education Fund\", \"P047\": \"Healthcare Savings\", \n",
        "    \"P048\": \"Property Investment\", \"P049\": \"Auto Insurance\"\n",
        "}\n",
        "\n",
        "df[\"Product_name\"] = df[\"Product_id\"].map(product_mapping)\n",
        "\n",
        "# Mapping interaction types\n",
        "interaction_type_mapping = {'Viewed': 1, 'Clicked': 2, 'Purchased': 3}\n",
        "df[\"Interaction_Type\"] = df[\"Interaction_type\"].map(interaction_type_mapping)\n",
        "\n",
        "# Surprise Reader for Surprise model compatibility\n",
        "reader = Reader(rating_scale=(1, 3))\n",
        "\n",
        "# Recommendation function\n",
        "def recommend_products(customer_id, model, interaction_data, product_mapping, n=5):\n",
        "    all_products = set(interaction_data['Product_id'].unique())\n",
        "\n",
        "    # Get customer's interacted products\n",
        "    interacted_products = set(interaction_data[interaction_data['Customer_id'] == customer_id]['Product_id'])\n",
        "    print(f\"Customer {customer_id} has interacted with: {interacted_products}\")  # Debugging line\n",
        "\n",
        "    # If the customer has no interactions, suggest popular products from all available products\n",
        "    products_to_predict = list(all_products - interacted_products) if customer_id in interaction_data['Customer_id'].values else list(all_products)\n",
        "\n",
        "    print(f\"Products to predict for customer {customer_id}: {products_to_predict}\")  # Debugging line\n",
        "\n",
        "    # If no products to predict, return empty\n",
        "    if not products_to_predict:\n",
        "        return pd.DataFrame(columns=['Product_Id', 'Product_Name'])\n",
        "\n",
        "    # Predictions for each product\n",
        "    predictions = [model.predict(customer_id, product_id) for product_id in products_to_predict]\n",
        "    \n",
        "    print(f\"Predictions for customer {customer_id}: {predictions}\")  # Debugging line\n",
        "    \n",
        "    # Sort predictions by estimated rating (highest first)\n",
        "    top_n_predictions = sorted(predictions, key=lambda x: x.est, reverse=True)[:n]\n",
        "    \n",
        "    # Get top recommended product IDs and names\n",
        "    recommended_product_ids = [pred.iid for pred in top_n_predictions]\n",
        "    recommended_products = pd.DataFrame({\n",
        "        'Product_Id': recommended_product_ids,\n",
        "        'Product_Name': [product_mapping.get(pid, 'Unknown') for pid in recommended_product_ids]\n",
        "    })\n",
        "    return recommended_products\n",
        "\n",
        "# Sidebar Navigation\n",
        "options = [\"PRODUCT RECOMMENDATIONS\"]\n",
        "selected = st.sidebar.selectbox(\"Select a page\", options)\n",
        "\n",
        "# Check if \"PRODUCT RECOMMENDATIONS\" page is selected\n",
        "if selected == \"PRODUCT RECOMMENDATIONS\":\n",
        "    col1, col2, col3 = st.columns([1, 2, 1])\n",
        "\n",
        "    with col2:\n",
        "        st.subheader(\"PRODUCT RECOMMENDATIONS\")\n",
        "\n",
        "        # Input field for Customer ID\n",
        "        customer_id = st.text_input(\"Enter Customer ID\", \"\")\n",
        "\n",
        "        # Button to get recommendations\n",
        "        if st.button(\"Get Recommendations\"):\n",
        "            if customer_id:\n",
        "                if customer_id in df['Customer_id'].values:\n",
        "                    recommendations = recommend_products(customer_id, model, df, product_mapping)\n",
        "\n",
        "                    if not recommendations.empty:\n",
        "                        st.markdown(\n",
        "                            f\"\"\"\n",
        "                            <div style=\"background-color: #d9f9d9; padding: 10px; border-radius: 10px;\">\n",
        "                                <h3 style=\"color: #000000; text-align: center;\">\n",
        "                                    Top Recommended Products for {customer_id}:\n",
        "                                </h3>\n",
        "                            </div>\n",
        "                            \"\"\",\n",
        "                            unsafe_allow_html=True\n",
        "                        )\n",
        "                        st.dataframe(recommendations)\n",
        "                    else:\n",
        "                        st.write(\"No recommendations available.\")\n",
        "                else:\n",
        "                    st.error(\"Invalid Customer ID. Please enter a valid Customer ID.\")\n",
        "            else:\n",
        "                st.warning(\"Please enter a valid Customer ID.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
